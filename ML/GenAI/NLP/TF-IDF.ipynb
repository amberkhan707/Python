{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86751bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "#Cleaning\n",
    "#lower\n",
    "#Tokenization/Splitting\n",
    "#Stemming/Lemmatization\n",
    "#stopwords\n",
    "#TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d386ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "import pandas as pd \n",
    "data = pd.read_csv('spam.csv', encoding = 'latin1')\n",
    "data = data.iloc[:,:-3]\n",
    "data.rename(columns={'v1':'label', 'v2':'review'},inplace = True)\n",
    "data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f4150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wn = WordNetLemmatizer()\n",
    "corpus = []\n",
    "\n",
    "for i in range(0,data.shape[0]):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', data['review'][i]) #Cleaning\n",
    "    review = review.lower() #lower\n",
    "    review = review.split() #tokenization\n",
    "    review = [wn.lemmatize(word) for word in review if word not in stopwords.words('english')]  #stopwords & Lemmatization/stemming\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "corpus;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e393179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'free entry': np.int64(13),\n",
       " 'claim call': np.int64(7),\n",
       " 'call claim': np.int64(1),\n",
       " 'free call': np.int64(12),\n",
       " 'chance win': np.int64(6),\n",
       " 'let know': np.int64(26),\n",
       " 'please call': np.int64(34),\n",
       " 'lt gt': np.int64(29),\n",
       " 'sorry call': np.int64(44),\n",
       " 'call later': np.int64(5),\n",
       " 'sorry call later': np.int64(45),\n",
       " 'hi hi': np.int64(23),\n",
       " 'customer service': np.int64(9),\n",
       " 'prize guaranteed': np.int64(40),\n",
       " 'guaranteed call': np.int64(20),\n",
       " 'valid hr': np.int64(48),\n",
       " 'prize guaranteed call': np.int64(41),\n",
       " 'selected receive': np.int64(42),\n",
       " 'private account': np.int64(37),\n",
       " 'private account statement': np.int64(38),\n",
       " 'urgent mobile': np.int64(47),\n",
       " 'call landline': np.int64(4),\n",
       " 'wat time': np.int64(49),\n",
       " 'new year': np.int64(32),\n",
       " 'send stop': np.int64(43),\n",
       " 'co uk': np.int64(8),\n",
       " 'lt decimal': np.int64(27),\n",
       " 'decimal gt': np.int64(10),\n",
       " 'lt decimal gt': np.int64(28),\n",
       " 'good morning': np.int64(15),\n",
       " 'good night': np.int64(16),\n",
       " 'po box': np.int64(36),\n",
       " 'last night': np.int64(25),\n",
       " 'pls send': np.int64(35),\n",
       " 'great day': np.int64(17),\n",
       " 'take care': np.int64(46),\n",
       " 'gt min': np.int64(19),\n",
       " 'lt gt min': np.int64(30),\n",
       " 'call land': np.int64(2),\n",
       " 'land line': np.int64(24),\n",
       " 'call land line': np.int64(3),\n",
       " 'gt lt': np.int64(18),\n",
       " 'free text': np.int64(14),\n",
       " 'prize claim': np.int64(39),\n",
       " 'ok lor': np.int64(33),\n",
       " 'every week': np.int64(11),\n",
       " 'happy new': np.int64(21),\n",
       " 'happy new year': np.int64(22),\n",
       " 'national rate': np.int64(31),\n",
       " 'await collection': np.int64(0)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=50,ngram_range=(2,3))\n",
    "\n",
    "X = tfidf.fit_transform(corpus).toarray()\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c3284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
